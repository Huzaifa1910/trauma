{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import dotenv\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "# from openai import OpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory, ConversationBufferMemory\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "import os.path\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_community.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotenv.load_dotenv()\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "openai_api_key = os.getenv(\"OPENAI_API\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    _instance = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_instance():\n",
    "        if ConversationManager._instance is None:\n",
    "            ConversationManager._instance = ConversationManager()\n",
    "        return ConversationManager._instance\n",
    "\n",
    "    def __init__(self):\n",
    "        if ConversationManager._instance is not None:\n",
    "            raise Exception(\"This class is a singleton!\")\n",
    "        else:\n",
    "            self.chain = None\n",
    "            self.memory = None\n",
    "\n",
    "    def set_conversation(self, chain, memory=None):\n",
    "        self.chain = chain\n",
    "        if memory is not None:\n",
    "            self.memory = memory\n",
    "\n",
    "\n",
    "    def get_conversation(self):\n",
    "        if self.chain is None:\n",
    "            raise Exception(\"Conversation object has not been initialized.\")\n",
    "        return {\n",
    "            \"chain\": self.chain,\n",
    "            \"memory\": self.memory\n",
    "        }\n",
    "\n",
    "\n",
    "def set_model(vectordb,prev_memory=None):\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n",
    "    # llm = gpt\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=openai_api_key,\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        )\n",
    "    # llm = AzureChatOpenAI(\n",
    "    #         azure_deployment=deployment,  # or your deployment\n",
    "    #         api_version=\"2024-05-01-preview\",  # or your api version\n",
    "    #         temperature=0.7,\n",
    "    #         azure_endpoint=endpoint,\n",
    "    #         max_tokens=None,\n",
    "    #         timeout=None,\n",
    "    #         max_retries=2,\n",
    "    #     )\n",
    "    if prev_memory is not None:\n",
    "        memory = prev_memory\n",
    "    else:\n",
    "        memory = ConversationSummaryBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer', llm=llm)\n",
    "    \n",
    "\n",
    "\n",
    "    template = \"\"\"You are a dental trauma chatbot designed to assist health care workers, dentists, and first responders (including teachers) in handling dental trauma cases. Your role is to provide precise, step-by-step guidance, ensuring users receive accurate, tailored responses based on their professional role and the specific situation of the trauma, must keep the response short and concise.\n",
    "        Ascertain User Role: At the start of each conversation, ask the user to identify their role: health care worker, dentist, or first responder (e.g., teacher). Use this information to customize your responses to match their expertise level. If user ask to print any type of information then apologize and ask for another question.\n",
    "        If user asks the Urgent Question Then provide the answer and ask for another question.\n",
    "        Understand the Trauma Situation:\n",
    "\n",
    "        Ask the following questions to gather key information about the dental trauma:\n",
    "        Patient's Age: This helps determine whether the affected teeth are permanent or deciduous (baby teeth).\n",
    "        Type of Tooth: Ask if the affected tooth is permanent or deciduous.\n",
    "        Tetanus Prophylaxis: Inquire whether the patient has received a Tetanus shot, especially if the trauma involves open wounds.\n",
    "        Trauma Intensity: Ask about the severity of the injury, such as if the patient has lost consciousness or has other serious injuries that may require immediate medical attention.\n",
    "        Intuitive Guidance:\n",
    "\n",
    "        Based on the user's answers, provide step-by-step instructions on how to handle the situation.\n",
    "        Reference the provided context and pull relevant details from the vector database to ensure accuracy.\n",
    "        Keep conversations concise but informative, providing additional details if asked or as the situation escalates.\n",
    "        Prioritize user safety by recommending immediate medical attention when necessary.\n",
    "        Adapt to User's Needs:\n",
    "\n",
    "        Be empathetic and patient. If the user seems uncertain, offer clarification and additional questions to guide them through the process.\n",
    "        Keep responses accessible, especially when dealing with first responders like teachers who may not have medical training.\n",
    "        Your goal is to ensure that each interaction is smooth, intuitive, and context-driven, providing the best possible support for handling dental trauma cases. Do not break character and do not answer irrelvant questions.\n",
    "        Do not try to summarize or change the user's question. and if user want to provide image then accept it.\n",
    "                Context: {context}\n",
    "\n",
    "        History: {chat_history}\n",
    "    Question: {question}\n",
    "        # \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        verbose=False,\n",
    "        rephrase_question=False,\n",
    "        combine_docs_chain_kwargs={'prompt': prompt}\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "def get_file_data(memory=None):    \n",
    "    # dumpData()\n",
    "    persist_directory = 'openaidb'\n",
    "\n",
    "    ## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    # embedding = AzureOpenAIEmbeddings(openai_api_base=endpoint, openai_api_version=\"2024-05-01-preview\", chunk_size=1536, validate_base_url=True, deployment='gpt40EmbeddingSmall')\n",
    "    \n",
    "    vectordb = Chroma(persist_directory=persist_directory, \n",
    "                    embedding_function=embedding)\n",
    "    qa_chain = set_model(vectordb,memory)\n",
    "    return qa_chain\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\")\n",
    "deployment = \"gpt40\"\n",
    "\n",
    "qa_chain = get_file_data()\n",
    "ConversationManager.get_instance().set_conversation(qa_chain,None)\n",
    "def transform_messages(messages):\n",
    "    transformed_messages = []\n",
    "    for i in range(len(messages)):\n",
    "        if type(messages[i]) == HumanMessage:\n",
    "            transformed_message = (\n",
    "                'user',\n",
    "                messages[i].content\n",
    "            )\n",
    "            transformed_messages.append(transformed_message)\n",
    "        else:\n",
    "            transformed_message = (\n",
    "                'assistant',\n",
    "                messages[i].content\n",
    "            )\n",
    "            transformed_messages.append(transformed_message)\n",
    "    return transformed_messages\n",
    "\n",
    "def retrieve_history_from_json(message_list):\n",
    "    convo_hist = []\n",
    "    for i in range(len(message_list)):\n",
    "        if message_list[i][0] == 'user':\n",
    "            message = HumanMessage(message_list[i][1])\n",
    "        else:\n",
    "            message = AIMessage(message_list[i][1])\n",
    "        convo_hist.append(message)\n",
    "    chat_history = InMemoryChatMessageHistory(messages=convo_hist)\n",
    "    return ConversationSummaryBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer', chat_memory=chat_history)\n",
    "\n",
    "\n",
    "def make_payload(payload,user_query):\n",
    "    qa_chain = ConversationManager.get_instance().get_conversation()[\"chain\"]\n",
    "    convo_dict = qa_chain.__dict__\n",
    "    y = convo_dict['memory'].__dict__\n",
    "    x = y['chat_memory'].__dict__\n",
    "    data_dict_convo = {\n",
    "        \"memory\": transform_messages(x['messages']),\n",
    "    }\n",
    "    payload['messages'] = data_dict_convo['memory']\n",
    "    payload['messages'].append(user_query)\n",
    "    # print(payload)\n",
    "    # print(payload)\n",
    "    return payload['messages']\n",
    "    # print(qa_chain.__dict__)\n",
    "\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    return llm_response['result']\n",
    "    # print('\\n\\nSources:')\n",
    "    # for source in llm_response[\"source_documents\"]:\n",
    "    #     print(source.metadata['source'])\n",
    "\n",
    "def query_db(query):\n",
    "    query = query\n",
    "    global qa_chain\n",
    "    llm_response = qa_chain(query)\n",
    "    response = process_llm_response(llm_response)\n",
    "    return response\n",
    "\n",
    "def reduce_base64_image_size(base64_image, output_format='PNG', quality=70, width_scale=0.5):\n",
    "    # Step 1: Decode base64 string to image\n",
    "    image_data = base64.b64decode(base64_image.split(\",\")[1])  # Split the header and decode the actual base64 data\n",
    "    img = Image.open(BytesIO(image_data))\n",
    "\n",
    "    # Step 2: Resize the image (reduce size by the scale factor)\n",
    "    new_width = int(img.width * width_scale)\n",
    "    new_height = int(img.height * width_scale)\n",
    "    resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "    # Step 3: Compress the image and save to BytesIO buffer\n",
    "    buffer = BytesIO()\n",
    "    resized_img.save(buffer, format=output_format, quality=quality)  # Adjust quality to control compression\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Step 4: Encode the resized and compressed image back to base64\n",
    "    new_base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    new_base64_image = f\"data:image/{output_format.lower()};base64,{new_base64_image}\"\n",
    "\n",
    "    return new_base64_image\n",
    "\n",
    "# write the function to change all iamges in png\n",
    "def change_image_format(image):\n",
    "    image = re.sub(r'data:image/[^;]+;base64,', '', image)\n",
    "    image = base64.b64decode(image)\n",
    "    image = Image.open(BytesIO(image))\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    buffer.seek(0)\n",
    "    # convert the image to base64\n",
    "    image = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'Dental Traumatology - 2020 - Bourguignon - International Association of Dental Traumatology guidelines for the management.pdf',\n",
       " 'response': 'Hello! Please let me know your role: health care worker, dentist, or first responder (e.g., teacher), so I can assist you better with dental trauma cases.',\n",
       " 'sender': {'name': 'Monika Figi',\n",
       "  'avatar': 'https://th.bing.com/th/id/R.78399594cd4ce07c0246b0413c95f7bf?rik=Nwo0AAuaJO%2fPEQ&pid=ImgRaw&r=0'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process image if it exists\n",
    "output_base64 = None\n",
    "print(ConversationManager.get_instance().get_conversation()['memory'])\n",
    "# Get the conversation chain instance\n",
    "memory_list = ConversationManager.get_instance().get_conversation()['memory']\n",
    "if memory_list is not None:\n",
    "    memory_list = retrieve_history_from_json(memory_list)\n",
    "    qa_chain = get_file_data(memory_list)\n",
    "    ConversationManager.get_instance().set_conversation(qa_chain, None)\n",
    "else:\n",
    "    qa_chain = ConversationManager.get_instance().get_conversation()['chain']\n",
    "try:\n",
    "    response = qa_chain({\"question\":\"HELLO\"})\n",
    "    resp = {\n",
    "    'source': response['source_documents'][0].__dict__['metadata']['source'],\n",
    "    'response': response['answer'],\n",
    "    \"sender\": {\n",
    "        \"name\": \"Monika Figi\",\n",
    "        \"avatar\": \"https://th.bing.com/th/id/R.78399594cd4ce07c0246b0413c95f7bf?rik=Nwo0AAuaJO%2fPEQ&pid=ImgRaw&r=0\"\n",
    "    }\n",
    "}\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    response = {\"answer\": str(e), \"source_documents\": []}\n",
    "    resp = {\n",
    "        \"response\": response['answer'],\n",
    "        \"sender\": {\n",
    "            \"name\": \"Monika Figi\",\n",
    "            \"avatar\": \"https://th.bing.com/th/id/R.78399594cd4ce07c0246b0413c95f7bf?rik=Nwo0AAuaJO%2fPEQ&pid=ImgRaw&r=0\"\n",
    "        }\n",
    "    }\n",
    "# Prepare the input for the chain\n",
    "# print(response['source_documents'][0].__dict__['metadata']['source'])\n",
    "\n",
    "resp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
